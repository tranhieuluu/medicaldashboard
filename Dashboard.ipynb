{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influenza Tracking Dashboard - Hieu Luu, 2024. This notebook is released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Influenza Disease Trackboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a disease tracking dashboard, built using UK Government data to visualise the virus Influenza effects on the UK population.\n",
    "\n",
    "According to the UK Health Security Agency (UKHSA), seasonal Influenza is a recurring illness that significantly contributes to the increased uptake and pressure on the NHS during the winter months. With this context, the dashboard is designed to visualize the impact of Influenza, highlighting its effects on the NHS across a number of years,through different seasons. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dashboard Methodology**\n",
    "\n",
    "1. The data is taken from the UKHSA Application Programming Interface (API), here: (https://ukhsa-dashboard.data.gov.uk/access-our-data/data-structure)\n",
    "\n",
    "2. Two key metrics were chosen, both of which are plotted on the y axis of the graph.\n",
    " \n",
    "    a. influenza_healthcare_ICUHDUadmissionRateByWeek\n",
    "        This is defined as: \"Influenza weekly admission rate of critical patients\", and the metric shows the weekly rate per 100,000 people of the total number of people with confirmed influenza admitted to a hospital Intensive Care Unit (ICU) or High Dependency Unit (HDU) in the 7 days up to and including the date shown.\n",
    "\n",
    "    b. influenza_testing_positivityByWeek\n",
    "        This is defined as: \"Influenza percentage of positive PCR tests in a 7 day period\" and the metric shows the percentage of the total number of PCR tests for influenza taken in the 7 days up to and including the date shown which had a positive result. Data is shown by the date that the test was taken (specimen date).\n",
    "\n",
    "3. The Python script is structured as below:\n",
    "\n",
    "    a. Using an API wrapper object to access and download the required data for the two metrics above, saving then in the json file named: \"admissions.json\" and \"testing.json\"\n",
    "\n",
    "    b. Clean and wrangle the data in order to get the two key fields, \"date\" and \"metric_value\"\n",
    "\n",
    "    c. Using the new wrangled data, plot two graphs visualising the two metrics over time. This was done using the pands and matplotlib library.\n",
    "    \n",
    "    d. Added a functionality for an interactive button to combine the two graphs into one for increased useability, along with an added \"refresh data\" button which will update the graph using the latest UKHSA data. This is done by utilising the API function defined before to update the ```dataframe```, without the need to overwrite the included json files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the APIwrapper class\n",
    "\n",
    "import requests\n",
    "import time\n",
    "\n",
    "class APIwrapper:\n",
    "    _access_point=\"https://api.ukhsa-dashboard.data.gov.uk\"\n",
    "    _last_access=0.0\n",
    "    \n",
    "    # Defining the data structure parameters, using the UKHSA datapath \n",
    "    def __init__(self, theme, sub_theme, topic, geography_type, geography, metric):\n",
    "        url_path=(f\"/themes/{theme}/sub_themes/{sub_theme}/topics/{topic}/geography_types/\" +\n",
    "                  f\"{geography_type}/geographies/{geography}/metrics/{metric}\")\n",
    "   \n",
    "        self._start_url=APIwrapper._access_point+url_path\n",
    "        self._filters=None\n",
    "        self._page_size=-1\n",
    "      \n",
    "        self.count=None\n",
    "# Function to get data on page, and also to filter page size, preventing IP ban\n",
    "    def get_page(self, filters={}, page_size=5):\n",
    "        if page_size > 365:\n",
    "            raise ValueError(\"Max supported page size is 365\")\n",
    "    \n",
    "        if filters != self._filters or page_size != self._page_size:\n",
    "            self._filters = filters\n",
    "            self._page_size = page_size\n",
    "            self._next_url = self._start_url\n",
    "    \n",
    "        if self._next_url is None: \n",
    "            return [] \n",
    "    \n",
    "        curr_time = time.time()\n",
    "        deltat = curr_time - APIwrapper._last_access\n",
    "        if deltat < 0.33: \n",
    "            time.sleep(0.33 - deltat)\n",
    "        APIwrapper._last_access = curr_time\n",
    "    \n",
    "        parameters = {x: y for x, y in filters.items() if y is not None}\n",
    "        parameters['page_size'] = page_size\n",
    "    \n",
    "        response = requests.get(self._next_url, params=parameters).json()\n",
    "    \n",
    "        self._next_url = response['next']\n",
    "        self.count = response['count']\n",
    "    \n",
    "        # Assign response['results'] to 'page_data' \n",
    "        page_data = response['results']\n",
    "    \n",
    "        return page_data\n",
    "# Loop the .getpage() to fetch all data pages in one go.\n",
    "    def get_all_pages(self, filters={}, page_size=365):\n",
    "        \n",
    "        data=[] \n",
    "        while True:\n",
    "           \n",
    "            next_page=self.get_page(filters, page_size)\n",
    "            if next_page==[]:\n",
    "                break \n",
    "            data.extend(next_page)\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and Query parameters set up for the 1st metric\n",
    "\n",
    "structure = {\n",
    "    \"theme\": \"infectious_disease\",\n",
    "    \"sub_theme\": \"respiratory\",\n",
    "    \"topic\": \"Influenza\",\n",
    "    \"geography_type\": \"Nation\",\n",
    "    \"geography\": \"England\"\n",
    "}\n",
    "structure[\"metric\"] = \"influenza_healthcare_ICUHDUadmissionRateByWeek\"\n",
    "\n",
    "\n",
    "# Filter for all ages\n",
    "filters = {\n",
    "    \"stratum\": None,\n",
    "    \"age\": \"all\",\n",
    "    \"sex\": None,\n",
    "    \"year\": None,\n",
    "    \"month\": None,\n",
    "    \"epiweek\": None,\n",
    "    \"date\": None,\n",
    "    \"in_reporting_delay_period\": None\n",
    "}\n",
    "\n",
    "# Initialise API Wrapper\n",
    "api = APIwrapper(**structure)\n",
    "\n",
    "# Fetch data from all pages\n",
    "admissions = api.get_all_pages(filters=filters)\n",
    "\n",
    "# Validate data - commented out for final version\n",
    "# print(f\"Data points expected: {api.count}\")\n",
    "# print(f\"Data points retrieved: {len(admissions)}\")\n",
    "\n",
    "# Test results - first 5 results - commented out for final version\n",
    "# print(\"First 5 results:\")\n",
    "# for case in admissions[:5]:  # Display the first 5 results\n",
    "#     print(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting up the 2nd metric\n",
    "\n",
    "structure = {\n",
    "    \"theme\": \"infectious_disease\",\n",
    "    \"sub_theme\": \"respiratory\",\n",
    "    \"topic\": \"Influenza\",\n",
    "    \"geography_type\": \"Nation\",\n",
    "    \"geography\": \"England\"\n",
    "}\n",
    "structure[\"metric\"] = \"influenza_testing_positivityByWeek\"\n",
    "\n",
    "\n",
    "# Filter for all ages\n",
    "filters = {\n",
    "    \"stratum\": None,\n",
    "    \"age\": \"all\",\n",
    "    \"sex\": None,\n",
    "    \"year\": None,\n",
    "    \"month\": None,\n",
    "    \"epiweek\": None,\n",
    "    \"date\": None,\n",
    "    \"in_reporting_delay_period\": None\n",
    "}\n",
    "\n",
    "# Initialise API Wrapper\n",
    "api = APIwrapper(**structure)\n",
    "\n",
    "# Fetch data from all pages\n",
    "testing = api.get_all_pages(filters=filters)\n",
    "\n",
    "# Validate data - commented out for final version\n",
    "# print(f\"Data points expected: {api.count}\")\n",
    "# print(f\"Data points retrieved: {len(testing)}\")\n",
    "\n",
    "# Test results - first 5 results - commented out for final version\n",
    "# print(\"First 5 results:\")\n",
    "# for case in testing[:5]:  # Display the first 5 results\n",
    "#     print(case)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the downloaded data into json files\n",
    "import json\n",
    "with open(\"admissions.json\", \"wt\") as OUTF:\n",
    "    json.dump(admissions, OUTF)\n",
    "\n",
    "with open(\"testing.json\", \"wt\") as OUTF:\n",
    "    json.dump(testing, OUTF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w3/w5xx13nn6gn53wq09lxtrwxh0000gn/T/ipykernel_34239/2338752104.py:58: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  timeseriesdf.fillna(0.0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Wrangling and cleaning up the data for the two metrics above\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import json\n",
    "\n",
    "# Embedding of matplotlib output\n",
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "\n",
    "# Loading the JOSN file\n",
    "with open(\"admissions.json\", \"rt\") as INFILE:\n",
    "    admissions=json.load(INFILE)\n",
    "\n",
    "with open(\"testing.json\", \"rt\") as INFILE:\n",
    "    testing=json.load(INFILE)    \n",
    "\n",
    "data={}\n",
    "for dataset in [admissions, testing]:\n",
    "    for entry in dataset:\n",
    "        date=entry['date']\n",
    "        metric=entry['metric']\n",
    "        value=entry['metric_value']\n",
    "        if date not in data:\n",
    "            data[date]={}\n",
    "        data[date][metric]=value\n",
    "\n",
    "# Extract and sort dates\n",
    "dates=list(data.keys())\n",
    "dates.sort()\n",
    "\n",
    "# Convert dates above to pandas type, finding the earliest and latest time\n",
    "def parse_date(datestring):\n",
    "    \"\"\" Convert a date string into a pandas datetime object \"\"\"\n",
    "    return pd.to_datetime(datestring, format=\"%Y-%m-%d\")\n",
    "\n",
    "startdate=parse_date(dates[0])\n",
    "enddate=parse_date(dates[-1])\n",
    "\n",
    "# Using the updated dates to define the dataframe with the two new columns\n",
    "index=pd.date_range(startdate, enddate, freq='D')\n",
    "timeseriesdf=pd.DataFrame(index=index, columns=['admissions', 'testing'])\n",
    "\n",
    "# translate the columns to the two metrics\n",
    "metrics ={'admissions': 'influenza_healthcare_ICUHDUadmissionRateByWeek',\n",
    "          'testing' :   'influenza_testing_positivityByWeek'}\n",
    "\n",
    "for date, entry in data.items(): \n",
    "    pd_date=parse_date(date)\n",
    "    for column in ['admissions','testing']: \n",
    "        metric_name=metrics[column]\n",
    "        # Insert a 0.0 if no value\n",
    "        value= entry.get(metric_name, 0.0)\n",
    "        timeseriesdf.loc[date, column]=value\n",
    "# fill in any remaining for any missing dates\n",
    "timeseriesdf.fillna(0.0, inplace=True)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Adding interactive controls - Refresh button\n",
    "\n",
    "# Refresh button set up\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import ipywidgets as wdg\n",
    "%matplotlib inline\n",
    "# make figures larger\n",
    "plt.rcParams['figure.dpi'] = 100\n",
    "# Create an Output widget to capture print statements here and also in the graph output down below in the next script\n",
    "output_widget = wdg.Output()\n",
    "\n",
    "# Defining the API access click back function\n",
    "def access_api(button):\n",
    "    with output_widget:  # Redirect output to the widget\n",
    "        clear_output(wait=True)  # Clear previous outputs\n",
    "        print(\"Fetching data from the API...\")\n",
    "    # Define the structure template\n",
    "        structure = {\n",
    "            \"theme\": \"infectious_disease\",\n",
    "            \"sub_theme\": \"respiratory\",\n",
    "            \"topic\": \"Influenza\",\n",
    "            \"geography_type\": \"Nation\",\n",
    "            \"geography\": \"England\"\n",
    "        }\n",
    "        \n",
    "        # Define metrics\n",
    "        metrics = {\n",
    "            'admissions': 'influenza_healthcare_ICUHDUadmissionRateByWeek',\n",
    "            'testing': 'influenza_testing_positivityByWeek'\n",
    "        }\n",
    "        \n",
    "        # Define filters\n",
    "        filters = {\n",
    "            \"stratum\": None,\n",
    "            \"age\": \"all\",\n",
    "            \"sex\": None,\n",
    "            \"year\": None,\n",
    "            \"month\": None,\n",
    "            \"epiweek\": None,\n",
    "            \"date\": None,\n",
    "            \"in_reporting_delay_period\": None\n",
    "        }\n",
    "    # Declare the global DataFrame\n",
    "        global timeseriesdf  \n",
    "\n",
    "        try:\n",
    "            data = {}  \n",
    "            \n",
    "            for column, metric_name in metrics.items():\n",
    "                # Update the structure with the current metric\n",
    "                structure[\"metric\"] = metric_name\n",
    "                \n",
    "                # Fetch new data from the API with filters applied and printing results\n",
    "                api = APIwrapper(**structure)\n",
    "                new_data = api.get_all_pages(filters=filters)  # Pass filters to API call\n",
    "                print(f\"Updated {len(new_data)} records for metric '{metric_name}'.\")\n",
    "                \n",
    "                # Extract only 'date' and 'metric_value' keys and organize into the 'data' dictionary\n",
    "                for entry in new_data:\n",
    "                    date = entry['date']\n",
    "                    value = entry.get('metric_value', 0.0)  \n",
    "                    if date not in data:\n",
    "                        data[date] = {}\n",
    "                    data[date][metric_name] = value\n",
    "\n",
    "            # Update the DataFrame with processed data\n",
    "            for date, entry in data.items():\n",
    "                pd_date = pd.to_datetime(date)\n",
    "                for column, metric_name in metrics.items():\n",
    "                    value = entry.get(metric_name, 0.0)  #\n",
    "                    timeseriesdf.loc[pd_date, column] = value\n",
    "\n",
    "            # Fill any remaining with 0.0\n",
    "            timeseriesdf.fillna(0.0, inplace=True)\n",
    "            print(\"Graph updated successfully with the latest UKHSA data.\")\n",
    "            \n",
    "            # Update the button to indicate success\n",
    "            apibutton.icon = \"check\"\n",
    "            apibutton.disabled = False \n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error while fetching data: {e}\")\n",
    "            apibutton.icon = \"times\"\n",
    "\n",
    "# Refresh button widget\n",
    "apibutton = wdg.Button(\n",
    "    description='Refresh data',\n",
    "    disabled=False,\n",
    "    button_style='', \n",
    "    tooltip='Click to download the latest metrics',\n",
    "    icon='download'\n",
    ")\n",
    "\n",
    "# Register the callback function with the button\n",
    "apibutton.on_click(access_api)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive graph\n",
    "\n",
    "Please use the buttons and options to interact with the graph, key features including:\n",
    "1. **Year selection** - Please click to choose the desired year.\n",
    "2. **Metric selection** - Please use control/command and right click to one/both metrics.\n",
    "3. **Scale selection** - Please click to choose either normal or log graphs.\n",
    "4. **Refresh data** - To update the graph with latest UKHSA data, please click on the refresh button, there will be comments below the graph to indicate the number of records which have been downloaded and updated, with a confirmation statement to confirm the update has been completed. Please then change the year/metric to update the graph with the latest data. (Please note that the updated data will not overwrite the exisitng json file and just update the graph)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "173e41732a7b46af8bb030ed682ef90e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Refresh data', icon='download', style=ButtonStyle(), tooltip='Click to download the latest…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b406f6e8307245d1a3ab23298b55f67e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Box(children=(Select(description='Year:', index=9, options=(2015, 2016, 2017, 2018, 2019, 2020, 2021, 2022, 20…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afd3fcf4c5024e27bab1ee3e22f93cbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1785334079d54914af442c745158c8d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Adding interactive controls - year, categogies and scale\n",
    "\n",
    "# Widget for year selection\n",
    "year = wdg.Select(\n",
    "    options=timeseriesdf.index.year.unique(),  \n",
    "    value=timeseriesdf.index.year[-1],        \n",
    "    rows=4,                                   \n",
    "    description='Year:',                      \n",
    "    disabled=False                            \n",
    ")\n",
    "\n",
    "# Widget for selecting data categories (admissions, testing)\n",
    "series = wdg.SelectMultiple(\n",
    "    options=['admissions', 'testing'],\n",
    "    value=['admissions', 'testing'],\n",
    "    rows=3,\n",
    "    description='Metrics:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Widget for selecting scale (linear or log)\n",
    "scale = wdg.RadioButtons(\n",
    "    options=['linear', 'log'],\n",
    "    description='Scale:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Combine controls into a box\n",
    "controls = wdg.Box([year, series, scale])\n",
    "\n",
    "# Main graph function\n",
    "def timeseries_graph(graphyear, gcols, gscale):\n",
    "    if gscale == 'linear':\n",
    "        logscale = False\n",
    "    else:\n",
    "        logscale = True\n",
    "    \n",
    "    # Filter the DataFrame for the selected year\n",
    "    yeardf = timeseriesdf[timeseriesdf.index.year == graphyear]\n",
    "    \n",
    "    ncols = len(gcols)\n",
    "    if ncols > 0:\n",
    "        # Plot the selected data for the filtered year\n",
    "        yeardf[list(gcols)].plot(logy=logscale)\n",
    "        plt.title(f\"Year: {graphyear}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Value\")\n",
    "        plt.grid(True, linestyle=\"--\", alpha=0.7)\n",
    "        plt.legend(loc=\"best\")\n",
    "        plt.show()  \n",
    "    else:\n",
    "        print(\"Click to select data for the graph\")\n",
    "        print(\"(Command/Ctrl-Click to select more than one test category)\")\n",
    "\n",
    "# Interactive output for the graph\n",
    "graph = wdg.interactive_output(\n",
    "    timeseries_graph, \n",
    "    {'graphyear': year, 'gcols': series, 'gscale': scale}\n",
    ")\n",
    "\n",
    "# Display widgets and the graph with comments confirmation\n",
    "display(apibutton,controls, graph, output_widget)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**License**\n",
    "\n",
    "\"Based on UK Government [data](https://ukhsa-dashboard.data.gov.uk/) published by the [UK Health Security Agency](https://www.gov.uk/government/organisations/uk-health-security-agency) and on the [DIY Disease Tracking Dashboard Kit](https://github.com/fsmeraldi/diy-covid19dash) by Fabrizio Smeraldi. Released under the [GNU GPLv3.0 or later](https://www.gnu.org/licenses/).\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
